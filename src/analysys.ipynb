{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohW56ywH0oSt",
        "outputId": "b3f60f98-1d17-48b4-8271-5c6c52a1b8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Set to false if you wish to use another platform or self host.\n",
        "USE_GOOGLE_COLLAB = True\n",
        "\n",
        "DATA_PATH = ''\n",
        "if USE_GOOGLE_COLLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATA_PATH = '/content/drive/MyDrive/creditcard.csv'\n",
        "else:\n",
        "    DATA_PATH = '../data/creditcard.csv'\n",
        "    raise Exception('Unimplemented.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Js7zfIr-zjW4"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GS0WKj2izjW6"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LEBz4Ku6zjW6"
      },
      "outputs": [],
      "source": [
        "az = data.drop('Class', axis=1)\n",
        "ay = data['Class']\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "x_res, y_res = smote.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EuixTzyu1kJT"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_res, y_res, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalizar os dados\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp8qGNu7zjW7"
      },
      "source": [
        "### Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X5ScsDtizjW7"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, x_train, x_test, y_train, y_test) -> dict:\n",
        "    start_time = time.time()\n",
        "    model.fit(x_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    results = {\n",
        "        'accuracy' : accuracy_score(y_test, y_pred),\n",
        "        'precision' : precision_score(y_test, y_pred),\n",
        "        'recall' : recall_score(y_test, y_pred),\n",
        "        'f1' : f1_score(y_test, y_pred),\n",
        "        'execution_time' : end_time - start_time,\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NeA92A21aM9"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o8L6_bbs1ZTX"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'SVM': SVC()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AY-N0mj2zjW8"
      },
      "outputs": [],
      "source": [
        "for name, model in models.items():\n",
        "    aresults[name] = evaluate_model(model, x_train, x_test, y_train, y_test)\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df # ???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjqIewpQ3sr5"
      },
      "source": [
        "### Separado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAx7U8VV3Jbz"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    accuracy, precision, recall, f1, exec_time = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'Execution Time': exec_time\n",
        "    }\n",
        "\n",
        "# Exibir os resultados\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1-9b1Er3qS5"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    accuracy, precision, recall, f1, exec_time = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'Execution Time': exec_time\n",
        "    }\n",
        "\n",
        "# Exibir os resultados\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmtdYCc83qVm"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    accuracy, precision, recall, f1, exec_time = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'Execution Time': exec_time\n",
        "    }\n",
        "\n",
        "# Exibir os resultados\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRm0mxP03qYk"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    accuracy, precision, recall, f1, exec_time = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'Execution Time': exec_time\n",
        "    }\n",
        "\n",
        "# Exibir os resultados\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP41ucz2355D"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'SVM': SVC()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    accuracy, precision, recall, f1, exec_time = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'Execution Time': exec_time\n",
        "    }\n",
        "\n",
        "# Exibir os resultados\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
